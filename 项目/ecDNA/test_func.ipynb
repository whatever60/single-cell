{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnyRandom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7478b90f7cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mzero_center\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msvd_solver\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnyRandom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mreturn_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0muse_highly_variable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AnyRandom' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse, spmatrix\n",
    "from scipy.sparse.linalg import LinearOperator, svds\n",
    "from sklearn.utils import check_array, check_random_state\n",
    "from sklearn.utils.extmath import svd_flip\n",
    "\n",
    "from anndata import AnnData\n",
    "\n",
    "from .. import logging as logg\n",
    "from ._utils import _get_mean_var\n",
    "from .._utils import AnyRandom\n",
    "from .. import settings\n",
    "\n",
    "\n",
    "def pca(\n",
    "    data: Union[AnnData, np.ndarray, spmatrix],\n",
    "    n_comps: Optional[int] = None,\n",
    "    zero_center: Optional[bool] = True,\n",
    "    svd_solver: str = 'arpack',\n",
    "    random_state: AnyRandom = 0,\n",
    "    return_info: bool = False,\n",
    "    use_highly_variable: Optional[bool] = None,\n",
    "    dtype: str = 'float32',\n",
    "    copy: bool = False,\n",
    "    chunked: bool = False,\n",
    "    chunk_size: Optional[int] = None,\n",
    ") -> Union[AnnData, np.ndarray, spmatrix]:\n",
    "    \"\"\"\\\n",
    "    Principal component analysis [Pedregosa11]_.\n",
    "    Computes PCA coordinates, loadings and variance decomposition.\n",
    "    Uses the implementation of *scikit-learn* [Pedregosa11]_.\n",
    "    .. versionchanged:: 1.5.0\n",
    "        In previous versions, computing a PCA on a sparse matrix would make a dense copy of\n",
    "        the array for mean centering.\n",
    "        As of scanpy 1.5.0, mean centering is implicit.\n",
    "        While results are extremely similar, they are not exactly the same.\n",
    "        If you would like to reproduce the old results, pass a dense array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        The (annotated) data matrix of shape `n_obs` × `n_vars`.\n",
    "        Rows correspond to cells and columns to genes.\n",
    "    n_comps\n",
    "        Number of principal components to compute. Defaults to 50, or 1 - minimum\n",
    "        dimension size of selected representation.\n",
    "    zero_center\n",
    "        If `True`, compute standard PCA from covariance matrix.\n",
    "        If `False`, omit zero-centering variables\n",
    "        (uses :class:`~sklearn.decomposition.TruncatedSVD`),\n",
    "        which allows to handle sparse input efficiently.\n",
    "        Passing `None` decides automatically based on sparseness of the data.\n",
    "    svd_solver\n",
    "        SVD solver to use:\n",
    "        `'arpack'` (the default)\n",
    "          for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`)\n",
    "        `'randomized'`\n",
    "          for the randomized algorithm due to Halko (2009).\n",
    "        `'auto'`\n",
    "          chooses automatically depending on the size of the problem.\n",
    "        `'lobpcg'`\n",
    "          An alternative SciPy solver.\n",
    "        .. versionchanged:: 1.4.5\n",
    "           Default value changed from `'auto'` to `'arpack'`.\n",
    "        Efficient computation of the principal components of a sparse matrix\n",
    "        currently only works with the `'arpack`' or `'lobpcg'` solvers.\n",
    "    random_state\n",
    "        Change to use different initial states for the optimization.\n",
    "    return_info\n",
    "        Only relevant when not passing an :class:`~anndata.AnnData`:\n",
    "        see “**Returns**”.\n",
    "    use_highly_variable\n",
    "        Whether to use highly variable genes only, stored in\n",
    "        `.var['highly_variable']`.\n",
    "        By default uses them if they have been determined beforehand.\n",
    "    dtype\n",
    "        Numpy data type string to which to convert the result.\n",
    "    copy\n",
    "        If an :class:`~anndata.AnnData` is passed, determines whether a copy\n",
    "        is returned. Is ignored otherwise.\n",
    "    chunked\n",
    "        If `True`, perform an incremental PCA on segments of `chunk_size`.\n",
    "        The incremental PCA automatically zero centers and ignores settings of\n",
    "        `random_seed` and `svd_solver`. If `False`, perform a full PCA.\n",
    "    chunk_size\n",
    "        Number of observations to include in each chunk.\n",
    "        Required if `chunked=True` was passed.\n",
    "    Returns\n",
    "    -------\n",
    "    X_pca : :class:`~scipy.sparse.spmatrix`, :class:`~numpy.ndarray`\n",
    "        If `data` is array-like and `return_info=False` was passed,\n",
    "        this function only returns `X_pca`…\n",
    "    adata : anndata.AnnData\n",
    "        …otherwise if `copy=True` it returns or else adds fields to `adata`:\n",
    "        `.obsm['X_pca']`\n",
    "             PCA representation of data.\n",
    "        `.varm['PCs']`\n",
    "             The principal components containing the loadings.\n",
    "        `.uns['pca']['variance_ratio']`\n",
    "             Ratio of explained variance.\n",
    "        `.uns['pca']['variance']`\n",
    "             Explained variance, equivalent to the eigenvalues of the\n",
    "             covariance matrix.\n",
    "    \"\"\"\n",
    "    start = logg.info(f'computing PCA')\n",
    "\n",
    "    # chunked calculation is not randomized, anyways\n",
    "    if svd_solver in {'auto', 'randomized'} and not chunked:\n",
    "        logg.info(\n",
    "            'Note that scikit-learn\\'s randomized PCA might not be exactly '\n",
    "            'reproducible across different computational platforms. For exact '\n",
    "            'reproducibility, choose `svd_solver=\\'arpack\\'.`'\n",
    "        )\n",
    "    data_is_AnnData = isinstance(data, AnnData)\n",
    "    if data_is_AnnData:\n",
    "        adata = data.copy() if copy else data\n",
    "    else:\n",
    "        adata = AnnData(data)\n",
    "\n",
    "    if use_highly_variable is True and 'highly_variable' not in adata.var.keys():\n",
    "        raise ValueError(\n",
    "            'Did not find adata.var[\\'highly_variable\\']. '\n",
    "            'Either your data already only consists of highly-variable genes '\n",
    "            'or consider running `pp.highly_variable_genes` first.'\n",
    "        )\n",
    "    if use_highly_variable is None:\n",
    "        use_highly_variable = True if 'highly_variable' in adata.var.keys() else False\n",
    "    if use_highly_variable:\n",
    "        logg.info('    on highly variable genes')\n",
    "    adata_comp = (\n",
    "        adata[:, adata.var['highly_variable']] if use_highly_variable else adata\n",
    "    )\n",
    "\n",
    "    if n_comps is None:\n",
    "        min_dim = min(adata_comp.n_vars, adata_comp.n_obs)\n",
    "        if settings.N_PCS >= min_dim:\n",
    "            n_comps = min_dim - 1\n",
    "        else:\n",
    "            n_comps = settings.N_PCS\n",
    "\n",
    "    logg.info(f'    with n_comps={n_comps}')\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    X = adata_comp.X\n",
    "\n",
    "    if chunked:\n",
    "        if not zero_center or random_state or svd_solver != 'arpack':\n",
    "            logg.debug('Ignoring zero_center, random_state, svd_solver')\n",
    "\n",
    "        from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "        X_pca = np.zeros((X.shape[0], n_comps), X.dtype)\n",
    "\n",
    "        pca_ = IncrementalPCA(n_components=n_comps)\n",
    "\n",
    "        for chunk, _, _ in adata_comp.chunked_X(chunk_size):\n",
    "            chunk = chunk.toarray() if issparse(chunk) else chunk\n",
    "            pca_.partial_fit(chunk)\n",
    "\n",
    "        for chunk, start, end in adata_comp.chunked_X(chunk_size):\n",
    "            chunk = chunk.toarray() if issparse(chunk) else chunk\n",
    "            X_pca[start:end] = pca_.transform(chunk)\n",
    "    elif (not issparse(X) or svd_solver == \"randomized\") and zero_center:\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        if issparse(X) and svd_solver == \"randomized\":\n",
    "            # This  is for backwards compat. Better behaviour would be to either error or use arpack.\n",
    "            logg.warning(\n",
    "                \"svd_solver 'randomized' does not work with sparse input. Densifying the array. \"\n",
    "                \"This may take a very large amount of memory.\"\n",
    "            )\n",
    "            X = X.toarray()\n",
    "        pca_ = PCA(\n",
    "            n_components=n_comps, svd_solver=svd_solver, random_state=random_state\n",
    "        )\n",
    "        X_pca = pca_.fit_transform(X)\n",
    "    elif issparse(X) and zero_center:\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        if svd_solver == \"auto\":\n",
    "            svd_solver = \"arpack\"\n",
    "        if svd_solver not in {'lobpcg', 'arpack'}:\n",
    "            raise ValueError(\n",
    "                'svd_solver: {svd_solver} can not be used with sparse input.\\n'\n",
    "                'Use \"arpack\" (the default) or \"lobpcg\" instead.'\n",
    "            )\n",
    "\n",
    "        output = _pca_with_sparse(\n",
    "            X, n_comps, solver=svd_solver, random_state=random_state\n",
    "        )\n",
    "        # this is just a wrapper for the results\n",
    "        X_pca = output['X_pca']\n",
    "        pca_ = PCA(n_components=n_comps, svd_solver=svd_solver)\n",
    "        pca_.components_ = output['components']\n",
    "        pca_.explained_variance_ = output['variance']\n",
    "        pca_.explained_variance_ratio_ = output['variance_ratio']\n",
    "    elif not zero_center:\n",
    "        from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "        logg.debug(\n",
    "            '    without zero-centering: \\n'\n",
    "            '    the explained variance does not correspond to the exact statistical defintion\\n'\n",
    "            '    the first component, e.g., might be heavily influenced by different means\\n'\n",
    "            '    the following components often resemble the exact PCA very closely'\n",
    "        )\n",
    "        pca_ = TruncatedSVD(\n",
    "            n_components=n_comps, random_state=random_state, algorithm=svd_solver\n",
    "        )\n",
    "        X_pca = pca_.fit_transform(X)\n",
    "    else:\n",
    "        raise Exception(\"This shouldn't happen. Please open a bug report.\")\n",
    "\n",
    "    if X_pca.dtype.descr != np.dtype(dtype).descr:\n",
    "        X_pca = X_pca.astype(dtype)\n",
    "\n",
    "    if data_is_AnnData:\n",
    "        adata.obsm['X_pca'] = X_pca\n",
    "        adata.uns['pca'] = {}\n",
    "        adata.uns['pca']['params'] = {\n",
    "            'zero_center': zero_center,\n",
    "            'use_highly_variable': use_highly_variable,\n",
    "        }\n",
    "        if use_highly_variable:\n",
    "            adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps))\n",
    "            adata.varm['PCs'][adata.var['highly_variable']] = pca_.components_.T\n",
    "        else:\n",
    "            adata.varm['PCs'] = pca_.components_.T\n",
    "        adata.uns['pca']['variance'] = pca_.explained_variance_\n",
    "        adata.uns['pca']['variance_ratio'] = pca_.explained_variance_ratio_\n",
    "        logg.info('    finished', time=start)\n",
    "        logg.debug(\n",
    "            'and added\\n'\n",
    "            '    \\'X_pca\\', the PCA coordinates (adata.obs)\\n'\n",
    "            '    \\'PC1\\', \\'PC2\\', ..., the loadings (adata.var)\\n'\n",
    "            '    \\'pca_variance\\', the variance / eigenvalues (adata.uns)\\n'\n",
    "            '    \\'pca_variance_ratio\\', the variance ratio (adata.uns)'\n",
    "        )\n",
    "        return adata if copy else None\n",
    "    else:\n",
    "        logg.info('    finished', time=start)\n",
    "        if return_info:\n",
    "            return (\n",
    "                X_pca,\n",
    "                pca_.components_,\n",
    "                pca_.explained_variance_ratio_,\n",
    "                pca_.explained_variance_,\n",
    "            )\n",
    "        else:\n",
    "            return X_pca\n",
    "\n",
    "\n",
    "def _pca_with_sparse(X, npcs, solver='arpack', mu=None, random_state=None):\n",
    "    random_state = check_random_state(random_state)\n",
    "    np.random.set_state(random_state.get_state())\n",
    "    random_init = np.random.rand(np.min(X.shape))\n",
    "    X = check_array(X, accept_sparse=['csr', 'csc'])\n",
    "\n",
    "    if mu is None:\n",
    "        mu = X.mean(0).A.flatten()[None, :]\n",
    "    mdot = mu.dot\n",
    "    mmat = mdot\n",
    "    mhdot = mu.T.dot\n",
    "    mhmat = mu.T.dot\n",
    "    Xdot = X.dot\n",
    "    Xmat = Xdot\n",
    "    XHdot = X.T.conj().dot\n",
    "    XHmat = XHdot\n",
    "    ones = np.ones(X.shape[0])[None, :].dot\n",
    "\n",
    "    def matvec(x):\n",
    "        return Xdot(x) - mdot(x)\n",
    "\n",
    "    def matmat(x):\n",
    "        return Xmat(x) - mmat(x)\n",
    "\n",
    "    def rmatvec(x):\n",
    "        return XHdot(x) - mhdot(ones(x))\n",
    "\n",
    "    def rmatmat(x):\n",
    "        return XHmat(x) - mhmat(ones(x))\n",
    "\n",
    "    XL = LinearOperator(\n",
    "        matvec=matvec,\n",
    "        dtype=X.dtype,\n",
    "        matmat=matmat,\n",
    "        shape=X.shape,\n",
    "        rmatvec=rmatvec,\n",
    "        rmatmat=rmatmat,\n",
    "    )\n",
    "\n",
    "    u, s, v = svds(XL, solver=solver, k=npcs, v0=random_init)\n",
    "    u, v = svd_flip(u, v)\n",
    "    idx = np.argsort(-s)\n",
    "    v = v[idx, :]\n",
    "\n",
    "    X_pca = (u * s)[:, idx]\n",
    "    ev = s[idx] ** 2 / (X.shape[0] - 1)\n",
    "\n",
    "    total_var = _get_mean_var(X)[1].sum()\n",
    "    ev_ratio = ev / total_var\n",
    "\n",
    "    output = {\n",
    "        'X_pca': X_pca,\n",
    "        'variance': ev,\n",
    "        'variance_ratio': ev_ratio,\n",
    "        'components': v,\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Literal, Tuple, Union\n",
    "\n",
    "from utils import gen_test_data\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import scipy.sparse.linalg as ssl\n",
    "import sklearn.utils as su\n",
    "import sklearn.metrics.pairwise as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gen_test_data()\n",
    "\n",
    "random_state = None\n",
    "random_state = su.check_random_state(random_state)\n",
    "np.random.set_state(random_state.get_state())\n",
    "random_init = np.random.rand(np.min(X.shape))\n",
    "\n",
    "mu = X.mean(0).A.flatten()[None, :]\n",
    "mdot = mu.dot\n",
    "mmat = mdot\n",
    "mhdot = mu.T.dot\n",
    "mhmat = mu.T.dot\n",
    "Xdot = X.dot\n",
    "Xmat = Xdot\n",
    "XHdot = X.T.conj().dot\n",
    "XHmat = XHdot\n",
    "ones = np.ones(X.shape[0])[None, :].dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matvec(x):\n",
    "    return Xdot(x) - mdot(x)\n",
    "\n",
    "def matmat(x):\n",
    "    return Xmat(x) - mmat(x)\n",
    "\n",
    "def rmatvec(x):\n",
    "    return XHdot(x) - mhdot(ones(x))\n",
    "\n",
    "def rmatmat(x):\n",
    "    return XHmat(x) - mhmat(ones(x))\n",
    "\n",
    "XL = LinearOperator(\n",
    "    matvec=matvec,\n",
    "    dtype=X.dtype,\n",
    "    matmat=matmat,\n",
    "    shape=X.shape,\n",
    "    rmatvec=rmatvec,\n",
    "    rmatmat=rmatmat,\n",
    ")\n",
    "u, s, v = svds(XL, solver='arpack', k=3, v0=random_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76460765, -0.31007793, -0.08696429],\n",
       "       [ 0.06440737, -0.39592239,  0.303778  ],\n",
       "       [ 0.38724412, -0.07124862, -0.8030008 ],\n",
       "       [-0.16932712,  0.85764623,  0.08871865],\n",
       "       [ 0.48228327, -0.08039728,  0.49746845]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5075521 , 2.22831194, 3.68579836])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33189392,  0.54958689, -0.29102236, -0.08252491,  0.47161172,\n",
       "        -0.47630417, -0.00479207, -0.12125475,  0.17172498, -0.05289501],\n",
       "       [-0.04131305, -0.17307923, -0.15273036, -0.31629146,  0.29856792,\n",
       "         0.4604311 , -0.07247979, -0.03326805,  0.71036363,  0.18125613],\n",
       "       [-0.28149533, -0.39407669,  0.01741264, -0.66254444,  0.26649959,\n",
       "        -0.38419357, -0.15985804, -0.00564081, -0.28610132,  0.01133558]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = svd_flip(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76460765, -0.31007793,  0.08696429],\n",
       "       [-0.06440737, -0.39592239, -0.303778  ],\n",
       "       [-0.38724412, -0.07124862,  0.8030008 ],\n",
       "       [ 0.16932712,  0.85764623, -0.08871865],\n",
       "       [-0.48228327, -0.08039728, -0.49746845]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33189392, -0.54958689,  0.29102236,  0.08252491, -0.47161172,\n",
       "         0.47630417,  0.00479207,  0.12125475, -0.17172498,  0.05289501],\n",
       "       [-0.04131305, -0.17307923, -0.15273036, -0.31629146,  0.29856792,\n",
       "         0.4604311 , -0.07247979, -0.03326805,  0.71036363,  0.18125613],\n",
       "       [ 0.28149533,  0.39407669, -0.01741264,  0.66254444, -0.26649959,\n",
       "         0.38419357,  0.15985804,  0.00564081,  0.28610132, -0.01133558]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = (u * s)[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = v[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33189392, -0.54958689,  0.29102236,  0.08252491, -0.47161172,\n",
       "         0.47630417,  0.00479207,  0.12125475, -0.17172498,  0.05289501],\n",
       "       [-0.04131305, -0.17307923, -0.15273036, -0.31629146,  0.29856792,\n",
       "         0.4604311 , -0.07247979, -0.03326805,  0.71036363,  0.18125613],\n",
       "       [ 0.28149533,  0.39407669, -0.01741264,  0.66254444, -0.26649959,\n",
       "         0.38419357,  0.15985804,  0.00564081,  0.28610132, -0.01133558]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = (u * s)[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32053283, -0.69095035,  1.15268587],\n",
       "       [-1.11966445, -0.8822386 , -0.09709746],\n",
       "       [ 2.95969904, -0.15876416, -0.58379069],\n",
       "       [-0.32699904,  1.91110332,  0.25526945],\n",
       "       [-1.83356838, -0.17915022, -0.72706716]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = s[idx] ** 2 / (X.shape[0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_get_mean_var(X, axis: Union[Literal['gene', 'cell'], int]):\n",
    "    if not isinstance(axis, int):\n",
    "        axis = 0 if axis == 'gene' else 1\n",
    "\n",
    "    if isinstance(X, ss.spmatrix):  # same as sparse.issparse()\n",
    "        X_copy = X.copy()\n",
    "        X_copy.data **= 2\n",
    "        mean = X.mean(axis=axis).A\n",
    "        var = X_copy.mean(axis=axis).A - mean ** 2\n",
    "        var *= X.shape[axis] / (X.shape[axis] - 1)\n",
    "    else:\n",
    "        mean = np.mean(X, axis=axis)\n",
    "        var = np.var(X, axis=axis, ddof=1)  # a little overhead (mean counted twice, but it's ok.)\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4661045134208863"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_get_mean_var(X, axis='cell')[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10).reshape(10, 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.99691169]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.99691169]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.11526048],\n",
       "       [ 1.3768974 ],\n",
       "       [36.12253499],\n",
       "       [33.14591219],\n",
       "       [ 7.2239534 ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.99691169]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5075521 , 2.22831194, 3.68579836])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matvec(x):\n",
    "    return X @ x - mu @ x\n",
    "#     return Xdot(x) - mdot(x)\n",
    "\n",
    "def matmat(x):\n",
    "    return X @ x - mu @ x\n",
    "#     return X @ x - mu @ X.T\n",
    "\n",
    "def rmatvec(x):\n",
    "    return X.T.conj() @ x - mu.T @ np.ones(X.shape[0])[np.newaxis, :] @ x\n",
    "#     return X.T.conj() @ x - mu.T @ (np.ones(X.shape[0])[None, :] @ x)\n",
    "#     return XHdot(x) - mhdot(ones(x))\n",
    "\n",
    "def rmatmat(x):\n",
    "    return X.T.conj() @ x - mu.T @ np.ones(X.shape[0])[np.newaxis, :] @ x\n",
    "#     return XHmat(x) - mhmat(ones(x))\n",
    "    \n",
    "XL = LinearOperator(\n",
    "    matvec=matvec,\n",
    "    dtype=X.dtype,\n",
    "    matmat=matmat,\n",
    "    shape=X.shape,\n",
    "    rmatvec=rmatvec,\n",
    "    rmatmat=rmatmat,\n",
    ")\n",
    "u, s, v = svds(XL, solver='arpack', k=3, v0=random_init)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5075521 , 2.22831194, 3.68579836])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.60621461, 1.61436382, 0.        ,\n",
       "        1.44374238, 0.36125158, 0.23907406, 0.        , 0.        ],\n",
       "       [0.        , 0.60726616, 0.38481562, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.29207223, 2.03855503, 0.        , 2.86626514, 0.        ,\n",
       "        1.81358986, 0.69463009, 0.        , 1.53118184, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.94502721,\n",
       "        1.86892043, 0.        , 0.        , 1.97284884, 0.4709345 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.80598835,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = gen_test_data((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.59036004, 0.66271167],\n",
       "       [1.17214564, 0.        , 0.        , 0.        , 0.88971561],\n",
       "       [0.75820333, 0.        , 2.72971747, 1.22219577, 0.        ],\n",
       "       [0.87893986, 0.84620373, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.93991671]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.17214564, 0.75820333, 1.4692999 , 0.66271167],\n",
       "       [1.17214564, 0.        , 0.        , 0.84620373, 0.88971561],\n",
       "       [0.75820333, 0.        , 5.45943494, 1.22219577, 0.        ],\n",
       "       [1.4692999 , 0.84620373, 1.22219577, 0.        , 0.        ],\n",
       "       [0.66271167, 0.88971561, 0.        , 0.        , 1.87983343]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.dia_matrix(Y + Y.T, 1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.setdiag(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.59036004, 0.66271167],\n",
       "       [1.17214564, 1.        , 0.        , 0.        , 0.88971561],\n",
       "       [0.75820333, 0.        , 1.        , 1.22219577, 0.        ],\n",
       "       [0.87893986, 0.84620373, 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.r2_score(Y.toarray(), Y.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((Y / Y.sum(axis=1)).A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.38265389,  0.13686109,  0.27411002,  0.26980894,\n",
       "         1.        ,  0.38265389,  0.13686109,  0.27411002,  0.26980894],\n",
       "       [ 0.38265389,  1.        , -0.72515244,  0.1824839 ,  0.27295455,\n",
       "         0.38265389,  1.        , -0.72515244,  0.1824839 ,  0.27295455],\n",
       "       [ 0.13686109, -0.72515244,  1.        ,  0.23205052, -0.58629324,\n",
       "         0.13686109, -0.72515244,  1.        ,  0.23205052, -0.58629324],\n",
       "       [ 0.27411002,  0.1824839 ,  0.23205052,  1.        , -0.60835327,\n",
       "         0.27411002,  0.1824839 ,  0.23205052,  1.        , -0.60835327],\n",
       "       [ 0.26980894,  0.27295455, -0.58629324, -0.60835327,  1.        ,\n",
       "         0.26980894,  0.27295455, -0.58629324, -0.60835327,  1.        ],\n",
       "       [ 1.        ,  0.38265389,  0.13686109,  0.27411002,  0.26980894,\n",
       "         1.        ,  0.38265389,  0.13686109,  0.27411002,  0.26980894],\n",
       "       [ 0.38265389,  1.        , -0.72515244,  0.1824839 ,  0.27295455,\n",
       "         0.38265389,  1.        , -0.72515244,  0.1824839 ,  0.27295455],\n",
       "       [ 0.13686109, -0.72515244,  1.        ,  0.23205052, -0.58629324,\n",
       "         0.13686109, -0.72515244,  1.        ,  0.23205052, -0.58629324],\n",
       "       [ 0.27411002,  0.1824839 ,  0.23205052,  1.        , -0.60835327,\n",
       "         0.27411002,  0.1824839 ,  0.23205052,  1.        , -0.60835327],\n",
       "       [ 0.26980894,  0.27295455, -0.58629324, -0.60835327,  1.        ,\n",
       "         0.26980894,  0.27295455, -0.58629324, -0.60835327,  1.        ]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(Y.toarray(), Y.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y  = gen_test_data((1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 420837 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1000000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y @Y @ Y @Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
